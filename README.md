# ETL-Data-Pipeline-using-HDFS-Hive-Scala
- Design a batch ETL job using HDFS and Hive

### Objective
The objectives of this project can be categorized as
- Design a full batch data pipeline
- How to use Hive to prepare raw data for data transformation
- How to use partitioning (sharding) in Hive

### Problem statement
We get the information of STM every day and need to run an ETL pipeline to enrich data for reporting
and analysis purpose in once a day batch job.
